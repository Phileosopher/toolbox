
## website - scrapers and archivers - cli python tools

[ListDownload](https://github.com/Alfystar/listDownload)
Python script to download multiple file in parallel thread.

[File-downloader](https://github.com/XniceCraft/file-downloader)
File downloader from python to download file only with CLI.

## website - scrapers and archivers - data policies tools

[GitHub - timlib/webXray: webXray is a tool for analyzing webpage traffic and content, extracting legal policies, and identifying the companies which collect user data.](https://github.com/timlib/webxray)

## website - scrapers and archivers - front-ends tools

[GitHub - machawk1/wail: :whale2: Web Archiving Integration Layer: One-Click User Instigated Preservation](https://github.com/machawk1/wail)
[Web Archiving Integration Layer (WAIL)](https://machawk1.github.io/wail/)

## website - scrapers and archivers - js tools

[nika-begiashvili/libarchivejs: Archive library for browsers](https://github.com/nika-begiashvili/libarchivejs)

## website - scrapers and archivers - links tools

[moarTLS Analyzer](https://chrome.google.com/webstore/detail/moartls-analyzer/ldfbacdbackkjhclmhnjabngnppnkagh/related)
addon which check all links on the webpage and show list of non-secure links
[Chrome Web Store - Search Results](https://chromewebstore.google.com/search/bayden)

[Investigo](https://github.com/tdh8316/Investigo)
A very simple and fast (written in #go) tool that searches for active links to social network accounts by username (or multiple usernames)

[GitHub - Sachin-v3rma/Astra: Astra is a tool to find URLs and secrets inside a webpage/files](https://github.com/Sachin-v3rma/Astra)

[GitHub - Igglybuff/awesome-piracy-bot: Set of bots for scraping URLs from Discord, Telegram, Reddit, and IRC.](https://github.com/Igglybuff/awesome-piracy-bot)
URL Scraping Tool

## website - scrapers and archivers - logs tools

[Log Harvestor](https://app.logharvestor.com/)

## website - scrapers and archivers - machine learning tools

[GPT-Powered Rotating Proxies API for Web Scraping | WebScraping.AI](https://webscraping.ai/)

## website - scrapers and archivers - photo-based tools

[ToolDatabase < Dmi < Foswiki](https://wiki.digitalmethods.net/Dmi/ToolDatabase)

[Visual Computing Group at the HTW Berlin](https://visual-computing.com/)

[GitHub - mxrch/darkshot: Lightshot scraper on steroids with OCR.](https://github.com/mxrch/darkshot)

## website - scrapers and archivers - programming resources tools

[GitHub - Obscurely/falion: An open source, programmed in rust, privacy focused tool for scraping programming resources (like stackoverflow) fast, efficient and asynchronous/parallel using the CLI or GUI.](https://github.com/Obscurely/falion)

## website - scrapers and archivers - publicly scraped content search - 15 tools

[Vandal](https://vegetableman.github.io/vandal/)
[Git](https://github.com/vegetableman/vandal)
[Vandal](https://chrome.google.com/webstore/detail/vandal/knoccgahmcfhngbjhdbcodajdioedgdo/related)
extension that makes working with Internet Archive faster, more comfortable, and more efficient.

[ReplayWeb.page](https://replayweb.page/)
[GitHub](https://github.com/webrecorder/replayweb.page)

[archive.fo](https://archive.fo/)

[Arquivo.pt - search pages from the past!](https://arquivo.pt/?l=en)

[Webpage archive](https://archive.li/)

[Archives Portal Europe Homepage](https://www.archivesportaleurope.net/)

[Stanford Web Archive Portal](https://swap.stanford.edu/)

[Archive-It - Web Archiving Services for Libraries and Archives](https://www.archive-it.org/)
[Wayback.archive-it.org](http://wayback.archive-it.org/)
[Archive-It - Explore Archived Content](https://www.archive-it.org/explore?show=Collections)
[Web Archiving with Archive-It CHoM Manual Harvard Wiki](https://wiki.harvard.edu/confluence/display/hmschommanual/Web+Archiving+with+Archive-It)

[Perma.cc](https://perma.cc/)
Archiving site meant for serious, academic research to preserve citations - free
Con: Relatively new, unclear what their content moderation policy is. Also doesn't work with Facebook
Permanent URLs

[Check and View Cached/Archived Web Pages - PageCached](https://pagecached.com/?url=stucky.tech)

[Archived Web - Visit offline websites by searching cached pages](https://archivedweb.com/)

[Web Archives - Chrome Web Store](https://chromewebstore.google.com/detail/web-archives/hkligngkgcpcolhcnkgccglchdafcnao)
extension for viewing cached web page version in 18 search engines and services

[See website cached version](https://stored.website/)

[Cached Web Pages â³ View old versions of any webpage](https://cachedpage.co/)

[Webpage archive](https://archive.ph/)
(archives web snapshots)

## website - scrapers and archivers - python tools

[Show HN: Crawlee for Python â€“ a web scraping and browser automation library | Hacker News](https://news.ycombinator.com/item?id=40913736)
[Crawlee for Python Â· Fast, reliable crawlers.](https://crawlee.dev/python/)

[GitHub - clips/pattern: Web mining module for Python, with tools for scraping, natural language processing, machine learning, network analysis and visualization.](https://github.com/clips/pattern)

## website - scrapers and archivers - self-hosting tools

[ArchiveBox](https://archivebox.io/)
[GitHub - ArchiveBox/ArchiveBox: Open source self-hosted web archiving. Takes URLs/browser history/bookmarks/Pocket/Pinboard/etc., saves HTML, JS, PDFs, media, and more...](https://github.com/ArchiveBox/ArchiveBox)
ðŸ—ƒ The open source self-hosted web archive. Takes browser history/bookmarks/Pocket/Pinboard/etc., saves HTML, JS, PDFs, media, and more...

[GitHub - xarantolus/Collect: A server to collect & archive websites that also supports video downloads](https://github.com/xarantolus/Collect)

[wallabag](https://wallabag.org/)
[WALLABAG](https://github.com/wallabag/wallabag)
Save and Classify Articles
A self-hosted read-it-later app
save web pages and read them later offline
[wallabag](https://github.com/wallabag/docker)
[wallabag](https://github.com/wallabag/ios-app)

## website - scrapers and archivers - social media tools

[Reaper | Social Media scraping tool](https://reaper.social/)

[JustGetMyData](https://justgetmydata.com/)
Links to Obtain Your Data from Websites

[GitHub soxoj/socid_extractor: Extract accounts info from personal pages on various sites for OSINT purpose](https://github.com/soxoj/socid_extractor)

[GitHub - champmq/TheScrapper: Scrape emails, phone numbers and social media accounts from a website.](https://github.com/champmq/TheScrapper)
Simple tool for scrapping emails and social media accounts from the website's source code.

## website - scrapers and archivers - spreadsheet output tools

[Listly - Free Web Data Scraper, Crawler, Extractor](https://www.listly.io/)
Webpage to Spreadsheet Converter
An extension that allows to collect all the data from a website into a table, quickly filter out the excess, and export the result to Excel/Google Sheet.
[Listly](http://listly.io/en/)
Fully-automated Web Scraping. HTML to Excel in seconds : Paste URL, Get Excel.

## website - scrapers and archivers - streaming media tools

[GitHub - Grandfather-Paradox/paramount-dl](https://github.com/Grandfather-Paradox/paramount-dl)

[GitHub - sc44/Stream-Recorder: TV stream player and recorder.](https://github.com/sc44/Stream-Recorder)

[GitHub - cotnw/muvi: A chrome extension to download movies directly from a Google search.](https://github.com/cotnw/muvi)

[sayem314/d-fi: A streaming music downloader. - NotABug.org: Free code hosting](https://notabug.org/sayem314/d-fi)

[zotify/zotify: A fast and customizable music and podcast downloader. - zotify - Zotify Git](https://zotify.xyz/zotify/zotify)

## website - scrapers and archivers - text and photos tools

[GitHub - lorenzodifuccia/safaribooks: Download and generate EPUB of your favorite books from O'Reilly Learning (aka Safari Books Online) library.](https://github.com/lorenzodifuccia/safaribooks)

[Image Extractor - extract.pics](https://extract.pics/)

[ExtractMailAddress](https://extractemailaddress.com/)
Extract Email's, URLs & Numbers from Text

## website - scrapers and archivers - The Internet Archive - 11 tools

[Classic Frontend](https://wayback-classic.net/)
[Script](https://github.com/overcast07/wayback-machine-spn-scripts)
[ArchiveTeam](https://tracker.archiveteam.org/)
Virtual Archiving Project

[GitHub - internetarchive/heritrix3: Heritrix is the Internet Archive's open-source, extensible, web-scale, archival-quality web crawler project.](https://github.com/internetarchive/heritrix3)
[Heritrix 3 Documentation - Heritrix 3 documentation](https://heritrix.readthedocs.io/en/latest/)]

[jjjake/internetarchive: A Python and Command-Line Interface to Archive.org](https://github.com/jjjake/internetarchive)

[internetarchive/wayback](https://github.com/internetarchive/wayback/tree/master/wayback-cdx-server)
Wayback CDX Server API - BETA
The wayback-cdx-server is a standalone HTTP servlet that serves the index that the wayback machine uses to lookup captures.

[Internet Archive Wayback Machine Link Ripper](https://tools.digitalmethods.net/beta/internetArchiveWaybackMachineLinkRipper/)
Enter a host or URL to retrieve the links to the URL's archived versions at [Wayback Machine](http://wayback.archive.org). A text file is produced which lists the archive URLs.

[GitHub - akamhy/waybackpy: Wayback Machine API interface & a command-line tool](https://github.com/akamhy/waybackpy)
If you want to write your own script to work with Internet Archive, check out the #python library Wayback Machine API. You can use it to quickly automate the extraction of all sorts of website data from the webarchive.

[GitHub - Haax9/WaybackPDF: OSINT tool to download archived PDF files from archive.org for a given website.](https://github.com/Haax9/WaybackPDF)
Collects a list of saved PDFs for the given domain from Internet Archive
and downloads them into a folder.

[GitHub - xnl-h4ck3r/waymore: Find way more from the Wayback Machine, Common Crawl, Alien Vault OTX, URLScan & VirusTotal!](https://github.com/xnl-h4ck3r/waymore)
Search archived links to domain in Wayback Machine and Common Crawl (+ Urlscan and Alien Vault OTX).

[GitHub - lorenzoromani1983/wayback-keyword-search: This tool downloads each page from the Wayback Machine for a specific domain and enables further keyword search on each saved page.](https://github.com/lorenzoromani1983/wayback-keyword-search)
A tool that allows you to download all the pages of a particular domain from Internet Archive for a particular month or day, and quickly do a keyword search on those pages.

[GitHub - mathis2001/WebHackUrls: Simple python OSINT tool for urls recon thanks to the waybackmachine.](https://github.com/mathis2001/WebHackUrls)
The simplest tool for URl recon with filter by keyword and saving results to file.

[ArchiveTeam Warrior | Hacker News](https://news.ycombinator.com/item?id=41141349)
[ArchiveTeam Warrior](https://warrior.archiveteam.org/)

## website - scrapers and archivers - torrent links tools

[GitHub - AlphaReign/scraper: AlphaReigns DHT Scraper, includes peer updater and categorizer](https://github.com/AlphaReign/scraper)
[AlphaReign](https://alphareign.com/)
[GitHub - AlphaReign/AlphaReign: Docs, About, Etc](https://github.com/AlphaReign/AlphaReign)
[GitHub - AlphaReign/www-php: The website of AlphaReign](https://github.com/AlphaReign/www-php)
[GitHub - AlphaReign/dht-server: AlphaReign's Torrent DHT Server](https://github.com/AlphaReign/dht-server)

## website - scrapers and archivers - websites - 32 tools

[Conifer](https://github.com/Rhizome-Conifer/conifer)
[Conifer | Homepage](https://conifer.rhizome.org/)
Web recorder

[archive.vn](https://archive.vn/)
[Webpage archive](https://archive.fo/)

[Ghostarchive, a website archive](https://ghostarchive.org/)

[Website Copier](https://websitecopier.net/)

[Guide](https://rentry.co/cloneasite)

[SingleFile: Save a complete web page into a single HTML file | Hacker News](https://news.ycombinator.com/item?id=30527999)
[gildas-lormeau/SingleFile: Web Extension for saving a faithful copy of a complete web page in a single HTML file](https://github.com/gildas-lormeau/SingleFile)
[SingleFileZ](https://github.com/gildas-lormeau/SingleFileZ)
Save Webpages as HTML

[CopySite](https://xdan.ru/copysite/)

[80legs - Customizable Web Scraping](https://80legs.com/)

[resurrect-pages](https://github.com/arantius/resurrect-pages)
[Albirew/resurrect-pages-isup-edition: A Firefox addon to expose cached copies of webpages, especially when they are unavailable.](https://github.com/Albirew/resurrect-pages-isup-edition)
[Resurrect Pages](https://addons.mozilla.org/en-US/firefox/addon/resurrect-pages)
[Resurrect Pages](https://addons.mozilla.org/nl/firefox/addon/resurrect-pages/)
View Archived/Cached Webpages

[Diffbot](https://www.diffbot.com/)
[Never Write Another Web Scraper](https://crawly.diffbot.com/)

[rahiel/archiveror: Archiveror will help you preserve the webpages you love.](https://github.com/rahiel/archiveror)

[Portia](https://scrapinghub.com/portia)
[Web Scraping Services for any size business](https://www.scrapinghub.com/data-services)

[CrawlMonster](https://www.crawlmonster.com/)

[BeautifulSoup](https://www.crummy.com/software/BeautifulSoup)
[Beautiful Soup Documentation - Beautiful Soup 4.4.0 documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc)

[MechanicalSoup/MechanicalSoup](https://github.com/MechanicalSoup/MechanicalSoup)

[GitHub - matiasb/demiurge: PyQuery-based scraping micro-framework.](https://github.com/matiasb/demiurge)
[demiurge â€” demiurge 0.2 documentation](https://demiurge.readthedocs.io/en/v0.2/)

[GitHub  psalias2006/Google2Csv: Google2Csv a simple google scraper that saves the results on a csv/xlsx/jsonl file](https://github.com/psalias2006/Google2Csv)

[Web Scraper](https://www.heliumscraper.com/en/index.php?p=home)

[PROWEBSCRAPER](https://prowebscraper.com/)

[Scrape web sites. Save to JSON, CSV /Dataflow kit](https://dataflowkit.com/dfk)

[archiveweb.page](https://archiveweb.page/)

[National Archives](http://www.nationalarchives.gov.uk/webarchive/)
UK Government Site Archive

[UKWA Home](https://www.webarchive.org.uk/ukwa)
[UKWA Home](https://www.webarchive.org.uk/)
UK Site Archive

[Webpage archive](https://archive.is/)

[Discover Any Email Address with Web Email Extractor Online Software](https://www.webemailextractor.com/)
extract email's and phone numbers from the website or list of website

[GitHub - motherboardgithub/mass_archive: A basic tool for pushing a web page to multiple archiving services at once.](https://github.com/motherboardgithub/mass_archive)

[SiteSucker for macOS](https://ricks-apps.com/osx/sitesucker/)
downloads complete websites

[Web Page to PDF - Convert Web to PDF Online Free](https://webtopdf.com/)
Convert Web Page to PDF

[Convert any URL or Web Page to PDF. Online HTML to PDF API service.](https://pdfmyurl.com/)
Convert Web Page to PDF

[Convert Web Page to PDF for Free Online - #1 Web to PDF Converter](https://www.web2pdfconvert.com/)

[Website Downloader | Website Copier | Site Downloader | Website Ripper](https://websitedownloader.io/)

[Getleft download | SourceForge.net](https://sourceforge.net/projects/getleftdown/)
